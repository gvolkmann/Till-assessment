# Till-assessment

1. I tired several different models and the Random Forest model I created was best at predicting the msrp for hybrid vehicles followed by the second Linear Regression model I created. The MAE or mean absolute error for the first Linear Regression model is 10472.735, meaning that the predictions generated by this model are around $10472.74 off from the actual msrp values for the vehicles. The variables that affect the model most strongly are acceleration, mpg, and year. Vehicles that can accelerate from 0-60 more quickly have a higher msrp, higher mpg also commands a higher price, and the year of a vehicle predicts the msrp as well. 

2. I tried 3 different models. Since Random Forest and XGBoost are robust models for handling continuous as well as categorical data I thought these might perfom well with the hybrid vehicle data. Random Forest is a very flexible model and does not require much tuning of parameters. Even after removing features with low coefficient values for my second Linear Regression model, it did not perform as well as the Random Forest. 

3. Year definitely has an impact on the msrp for the vehicle, however, I did not analyze this variable as a categorical variable since this would cause cars in years such as 2000 and 2001 to fit into the model very well since there are very few cars that were made in this year in the dataset, whereas there is a large range in msrp for cars from 2008 or 2013 since there is a larger number of cars from these years. I attempted a model with year as a categorical variable and found that although the results were better, I think this is because any predictions for vehicles from a year with very few data points are much more likely to be counted as "correct", even though this would not be true most likely for a real life scenario. 
I also dropped the mpgmpge variable as there was an exact correlation with the mpg variable, which could lead to multicollinearity signal in the model since the two variables are so closely linked. I also dropped carclassid in favor of one-hot encoding the carclass variable, since carclassid is a numerical variable and this might show up as signal even though the numbers do not hold actual weight and represent categories, not numerical data. I also removed the vehicle variable since there are 109 different types of vehicles for 153 data points, so including this metric might result in overfitting of the data since many data points for the vehicle variable are the only one for that particular type. 
With more time for this project, I would look into engine power for each type of vehicle, and I would look up all the models and add the make of car as a variable. 

4. Variables that have explanatory power based on Random Forest Algorithm: 

![random forest coefficients](https://user-images.githubusercontent.com/66225041/138615698-e29abdcf-d8a7-4f86-aaa0-5869dc48f27f.png)

I am not surprised that the Acceleration variable has such a high explanatory value since people willing to pay a premium for their vehicles want a vehicle with fast acceleration. This is a quality seen in luxury cars and can also indicate manufacturing quality as well, so it makes sense that these vehicles would sell for a higher msrp. A higher mpg amount means that the car will be more economical to operate, so it makes sense that this would result in higher msrp amounts. It also makes sense that the year affects price since ostensibly newer cars would cost more in general. There is quite a large range for car prices based on year however, so I'm not surprised that this variable alone is not more indicative of price. 

5. I am fairly confident in my model's fit. It had the highest explained variance score of the models I created. For future models, I would want to add make of vehicle as a variable and perhaps look into the engine power for the various models.  
